{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd, init\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from mxboard import *\n",
    "from mxnet.gluon import data as gdata\n",
    "import os\n",
    "from mxnet.gluon import nn\n",
    "import numpy as np\n",
    "import random\n",
    "from mxnet.gluon import loss\n",
    "from mxnet.gluon.trainer import Trainer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    root = 'data/raw_exp'\n",
    "    file_list = os.listdir(root)\n",
    "    file_labels = dict(zip(file_list, list(range(1,len(file_list)+1))))\n",
    "    samples_list = []\n",
    "\n",
    "    for file in file_list:\n",
    "        with open(os.path.join(root,file), 'r') as f:\n",
    "            first_row = f.readline()\n",
    "            first_row = first_row.strip().split('\\t')\n",
    "            for sample in first_row[1:]:\n",
    "                if int(sample.strip()[-3:-2]) == 0:\n",
    "                    # case\n",
    "                    samples_list.append((sample, file_labels[file]))\n",
    "                else:\n",
    "                    # control\n",
    "                    samples_list.append((sample, 0))\n",
    "    sample2labels = pd.DataFrame(samples_list,columns=['sampleID', 'label'])\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_sample(np.array(sample2labels['sampleID']).reshape(-1, 1), \n",
    "                                              np.array(sample2labels['label'])\n",
    "                                             ) # 过采样\n",
    "    allsamples = pd.DataFrame({'sampleID':X_resampled[:,0], 'label':y_resampled})\n",
    "    length = allsamples.shape[0]\n",
    "    index_list = list(range(length))\n",
    "    train_num, validation_num, test_num= 0.7, 0.2, 0.1\n",
    "    random.shuffle(index_list)\n",
    "    train_index = index_list[0:int(length*train_num)]\n",
    "    validation_index = index_list[int(length*train_num): int(length*train_num) + int(length*validation_num)]\n",
    "    test_index = index_list[int(length * train_num) + int(length * validation_num):]\n",
    "\n",
    "    train_samples = allsamples.loc[train_index]\n",
    "    validation_samples = allsamples.loc[validation_index]\n",
    "    test_samples = allsamples.loc[test_index]\n",
    "    \n",
    "    return train_samples, validation_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pd.read_csv('data/exp_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, validation_samples, test_samples = load_all_data()\n",
    "train_x = nd.array(exp[train_samples['sampleID']]).transpose()\n",
    "train_y = nd.array(train_samples['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(3000, activation='relu'),\n",
    "        nn.BatchNorm(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Dense(1000, activation='relu'),\n",
    "        nn.BatchNorm(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Dense(100, activation='relu'),\n",
    "        nn.BatchNorm(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Dense(33))\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter dense0_weight (shape=(3000, 0), dtype=float32)\n",
       "  Parameter dense0_bias (shape=(3000,), dtype=float32)\n",
       "  Parameter dense1_weight (shape=(1000, 0), dtype=float32)\n",
       "  Parameter dense1_bias (shape=(1000,), dtype=float32)\n",
       "  Parameter dense2_weight (shape=(100, 0), dtype=float32)\n",
       "  Parameter dense2_bias (shape=(100,), dtype=float32)\n",
       "  Parameter dense3_weight (shape=(33, 0), dtype=float32)\n",
       "  Parameter dense3_bias (shape=(33,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params('.*dense.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = Trainer(net.collect_params(), 'adam', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "dataset = gdata.ArrayDataset(train_x, train_y)\n",
    "data_iter = gdata.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.8110, train acc 0.755,  time 142.8 sec\n",
      "epoch 2, loss 0.3232, train acc 0.897,  time 137.9 sec\n",
      "epoch 3, loss 0.2348, train acc 0.925,  time 140.3 sec\n",
      "epoch 4, loss 0.2226, train acc 0.936,  time 146.5 sec\n",
      "epoch 5, loss 0.2201, train acc 0.945,  time 158.2 sec\n",
      "epoch 6, loss 0.3120, train acc 0.938,  time 184.6 sec\n",
      "epoch 7, loss 0.3026, train acc 0.947,  time 214.7 sec\n",
      "epoch 8, loss 0.3173, train acc 0.950,  time 195.7 sec\n",
      "epoch 9, loss 0.5553, train acc 0.926,  time 192.7 sec\n",
      "epoch 10, loss 0.4940, train acc 0.936,  time 194.1 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f8f3ed57518b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtrain_loss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mtrain_acc_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The current array is not a scalar\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python36\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1979\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1980\u001b[1;33m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[0;32m   1981\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "sw = SummaryWriter(logdir='./logs2', flush_secs=2)\n",
    "params = net.collect_params('.*dense.*')\n",
    "param_names = params.keys()\n",
    "ls = 0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss_sum, train_acc_sum, n, start = 0., 0., 0., time.time()\n",
    "    for X, Y in data_iter:\n",
    "        with autograd.record():\n",
    "            pre = net(X)\n",
    "            l = cross_entropy(pre, Y).sum()\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "        train_loss_sum += l.sum().asscalar()\n",
    "        train_acc_sum += (pre.argmax(axis=1)==Y).sum().asscalar()\n",
    "        n += len(Y)\n",
    "        \n",
    "        sw.add_histogram(tag='cross_entropy', values=train_loss_sum / n, global_step=ls)\n",
    "        sw.add_histogram(tag='train_acc', values=train_acc_sum / n, global_step=ls)\n",
    "        \n",
    "        for i, name in enumerate(param_names):\n",
    "            sw.add_histogram(tag=name, values=net.collect_params()[name].grad(), global_step=ls, bins=1000) \n",
    "        ls += 1\n",
    "    print('epoch %d, loss %.4f, train acc %.3f,  time %.1f sec' % \n",
    "          (epoch, train_loss_sum / n, train_acc_sum / n,  time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in data_iter:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.09682716 -0.06125428 -0.00473381 ... -0.0888713  -0.00932187\n",
       "  -0.15131769]\n",
       " [-0.0924625  -0.07597667  0.01104103 ... -0.06827219 -0.00386821\n",
       "  -0.13062906]\n",
       " [-0.09791607 -0.08168846 -0.00248691 ... -0.09105153 -0.01040389\n",
       "  -0.12076826]\n",
       " ...\n",
       " [-0.08215083 -0.07469714 -0.00171283 ... -0.10362029 -0.01176906\n",
       "  -0.13257726]\n",
       " [-0.09476141 -0.08650095 -0.0232383  ... -0.06999294 -0.00254738\n",
       "  -0.13142964]\n",
       " [-0.07482515 -0.0936146  -0.01798228 ... -0.04998816 -0.0169401\n",
       "  -0.1297883 ]]\n",
       "<NDArray 200x33 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 0. 15. 17. 31. 16.  8.  6. 13.  2. 17. 27. 28. 11.  0. 25. 31.  8.  1.\n",
       " 19. 18. 12.  0. 31. 11. 15. 10. 11.  1.  3.  2. 12. 31. 22. 25. 26. 11.\n",
       " 18.  7. 23. 22. 12. 11.  8.  4. 12. 18.  0. 15. 30.  4. 22.  0. 26.  5.\n",
       "  4.  1. 19.  7. 19.  1. 30. 29.  7. 30. 10. 14. 19. 10. 14.  9. 13.  4.\n",
       " 21. 31.  8. 21.  7. 22.  8. 28. 14. 22. 21. 19. 20. 18. 21. 25.  5. 32.\n",
       " 12.  0. 24. 22. 30. 22. 25.  8. 27. 26. 15.  7.  9.  7. 32. 27. 17. 17.\n",
       " 13. 25. 18. 10.  5. 20. 22. 11. 21. 30. 14. 28. 25. 18. 28. 14. 24. 25.\n",
       "  0.  4. 21. 26. 14.  0. 22. 20. 12. 24. 25.  4. 32.  9. 19.  6.  3. 23.\n",
       "  8. 23. 21.  2. 13. 21.  2. 30. 14. 12.  5. 25. 14. 14. 31. 13. 13.  5.\n",
       " 21. 30. 21. 10. 14.  9. 10. 20. 18. 19.  2.  5. 28. 32. 31. 22. 20. 25.\n",
       " 19.  0. 26. 20. 15. 26.  2. 27. 30. 20. 23. 12. 30. 21.  8. 31. 30.  2.\n",
       " 17.  8.]\n",
       "<NDArray 200 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " ...\n",
       " [0. 0. 1. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]]\n",
       "<NDArray 200x33 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_h = nd.zeros(shape=(y.shape[0],33))\n",
    "for i, x in enumerate(y):\n",
    "    y_h[i, x] = 1\n",
    "    \n",
    "y_h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
